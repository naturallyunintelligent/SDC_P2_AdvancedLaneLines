{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Advanced Lane Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import various required packages:\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib qt  \n",
    "import pickle\n",
    "%matplotlib inline  \n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *First Things First - Camera Calibration Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring functions up to here\n",
    "\n",
    "def camera_cal(images):\n",
    "\n",
    "    #* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            #write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "            #cv2.imwrite(write_name, img)\n",
    "            cv2.imshow('img', img)\n",
    "            cv2.waitKey(500)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "    \n",
    "    \n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"ret\"] = ret\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    dist_pickle[\"rvecs\"] = rvecs\n",
    "    dist_pickle[\"tvecs\"] = tvecs\n",
    "\n",
    "    pickleFile = open( \"camera_cal/camera_cal pickle.p\", \"wb\" ) \n",
    "    pickle.dump( dist_pickle, pickleFile )\n",
    "    pickleFile.close()\n",
    "    \n",
    "    return   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Optional Function: quick check of camera_cal by undistorting an image*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistTest(imageName, pickleName):\n",
    "    # Test undistortion on a chosen image\n",
    "    img = cv2.imread(imageName)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # open camera cal pickle file for reading\n",
    "    pickleFile = open(pickleName,'rb')  \n",
    "    # load the object from the file into var\n",
    "    camera_cal = pickle.load(pickleFile)  \n",
    "\n",
    "    mtx = camera_cal[\"mtx\"]\n",
    "    dist = camera_cal[\"dist\"]\n",
    "\n",
    "    pickleFile.close()\n",
    "    \n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    cv2.imwrite('output_images/undistortedTestImage.jpg',undist)\n",
    "\n",
    "    #dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(undist)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Pipeline Function 1 - Undistort raw images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def undist_raw(rawimages):\n",
    "    #fname = 'test_images/test1.jpg'\n",
    "\n",
    "    # open camera cal pickle file for reading\n",
    "    pickleFile = open(\"camera_cal/camera_cal pickle.p\",'rb')  \n",
    "    # load the object from the file into var\n",
    "    camera_cal = pickle.load(pickleFile)  \n",
    "\n",
    "    mtx = camera_cal[\"mtx\"]\n",
    "    dist = camera_cal[\"dist\"]\n",
    "\n",
    "    pickleFile.close()\n",
    "\n",
    "    for idx, fname in enumerate(rawimages):\n",
    "        img = cv2.imread(fname)\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        #filename = Path(fname)\n",
    "        #filename_wo_ext = filename.with_suffix('')\n",
    "\n",
    "        undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "        #cv2.imshow('undist', undist)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "\n",
    "        #filename = '/home/user/somefile.txt'\n",
    "        #print( filename.rsplit( \".\", 1 )[ 0 ] )\n",
    "        # '/home/user/somefile'\n",
    "\n",
    "        fname_wo_ext = fname.rsplit( \".\", 1 )[ 0 ] \n",
    "        fname_wo_path = fname_wo_ext.rsplit( \"/\", 1 )[ 1 ]\n",
    "\n",
    "        #path = os.path.join(base_dir, fname_undist)\n",
    "        cv2.imwrite( \"output_images/\"+fname_wo_path + \"_undist.jpg\",undist)\n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Function 2 - Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshBinImgs (undistImages, threshS=(0,255), threshSobel=(0,255)):\n",
    "    \n",
    "    for idx, fname in enumerate(undistImages):\n",
    "        img = cv2.imread(fname)\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        \n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        cv2.imshow('hls', hls)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "        #H = hls[:,:,0]\n",
    "        #L = hls[:,:,1]\n",
    "        S = hls[:,:,2]\n",
    "        #cv2.imshow('S', S)\n",
    "        #cv2.waitKey(500)\n",
    "        \n",
    "        S_binary = np.zeros_like(S)\n",
    "        S_binary[(S > threshS[0]) & (S <= threshS[1])] = 1\n",
    "        \n",
    "        #cv2.imshow('binary', 255*S_binary)\n",
    "        #cv2.waitKey(500)\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Sobel x\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "        abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "        scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "        # Threshold x gradient\n",
    "        sxbinary = np.zeros_like(scaled_sobel)\n",
    "        sxbinary[(scaled_sobel >= threshSobel[0]) & (scaled_sobel <= threshSobel[1])] = 1\n",
    "        \n",
    "        # Stack each channel to view their individual contributions in green and blue respectively\n",
    "        # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "        color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, S_binary)) * 255\n",
    "\n",
    "        # Combine the two binary thresholds\n",
    "        combined_binary = np.zeros_like(sxbinary)\n",
    "        combined_binary[(S_binary == 1) | (sxbinary == 1)] = 1\n",
    "\n",
    "        #cv2.imshow('combined_binary', 255*combined_binary)\n",
    "        #cv2.waitKey(500)\n",
    "        \n",
    "        # Plotting thresholded images\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "        ax1.set_title('Stacked thresholds')\n",
    "        ax1.imshow(color_binary)\n",
    "\n",
    "        ax2.set_title('Combined S channel and gradient thresholds')\n",
    "        ax2.imshow(combined_binary, cmap='gray')\n",
    "        \n",
    "        fname_wo_ext = fname.rsplit( \".\", 1 )[ 0 ] \n",
    "        fname_wo_path = fname_wo_ext.rsplit( \"/\", 1 )[ 1 ]\n",
    "        #print(\"outputimages/\"+fname_wo_path + \"_binary.jpg\")\n",
    "        \n",
    "        isWritten = cv2.imwrite( \"output_images/\"+fname_wo_path + \"_binary.jpg\", 255*combined_binary)\n",
    "        #if isWritten:\n",
    "        #    print('Image is successfully saved as file.')\n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Function 3 - Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Getting Started: Calibrate the camera (and check an image if required)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of calibration images\n",
    "calimages = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Calibrate the camera\n",
    "camera_cal(calimages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional check\n",
    "\n",
    "#fileName = 'camera_cal/calibration1.jpg'\n",
    "#pickleName = \"camera_cal/camera_cal pickle.p\"\n",
    "#undistTest(fileName, pickleName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Running the Pipeline:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Apply a distortion correction to the raw test images.\n",
    "\n",
    "#base_dir = 'test_images'\n",
    "rawimages = glob.glob('test_images/*.jpg')\n",
    "\n",
    "undist_raw(rawimages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "\n",
    "undistImages = glob.glob('output_images/*_undist.jpg')\n",
    "threshS = (100, 255)\n",
    "threshSobel=(20,100)\n",
    "\n",
    "threshBinImgs(undistImages, threshS, threshSobel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-24b5421e96bc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-24b5421e96bc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    * Apply a perspective transform to rectify binary image (\"birds-eye view\").\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "\n",
    "\n",
    "def transform (images)\n",
    "    \n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        \n",
    "        #Compute the perspective transform, M, given source and destination points:\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "        #Compute the inverse perspective transform:\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "        #Warp an image using the perspective transform, M:\n",
    "        warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        #Note: When you apply a perspective transform, choosing four source points manually, as we did in this video, is often not the best option. There are many other ways to select source points. For example, many perspective transform algorithms will programmatically detect four source points in an image based on edge or corner detection and analyzing attributes like color and surrounding pixels.\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "binaryImages = glob.glob('output_images/*_binary.jpg')\n",
    "\n",
    "transform(binaryImages)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
